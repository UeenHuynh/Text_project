{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "remove_characters = '\\t”“' + string.punctuation\n",
    "def text_normalize(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    for char in remove_characters:\n",
    "        text = text.replace(char, '')\n",
    "    \n",
    "    return text\n",
    "\n",
    "def create_dictionary(corpus):\n",
    "    dictionary = []\n",
    "    for paragraph in corpus:\n",
    "        paragraph = text_normalize(paragraph1)\n",
    "        tokens = paragraph.split()\n",
    "        for token in tokens:\n",
    "            if token not in dictionary:\n",
    "                dictionary.append(token)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def vectorize(text, dictionary, unknown_token_id):\n",
    "    text = text_normalize(text)\n",
    "    tokens = text.split()\n",
    "    vector = [\n",
    "        dictionary.index(token) \\\n",
    "        if token in dictionary else unknown_token_id \\\n",
    "            for token in tokens\n",
    "    ]\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = []\n",
    "text = 'thư viện'\n",
    "unknown_token_id = len(dictionary)\n",
    "vectorize(text, dictionary, unknown_token_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"\n",
    "Hướng nhìn về tương lai của Văn học Pháp tại Việt Nam\n",
    "\n",
    "NXB Tri thức và Viện Pháp tại Hà Nội vừa tổ chức Tọa đàm 'Dấu ấn văn hóa Pháp qua một số tác phẩm xuất bản tại Việt Nam'.\n",
    "\n",
    "Tham dự Tọa đàm Dấu ấn văn hóa Pháp qua một số tác phẩm xuất bản tại Việt Nam, có ba diễn giả: PGS.TS Phùng Ngọc Kiên, Trưởng Ban Văn học Nước ngoài, Viện Văn học; TS. Dịch giả Nguyễn Giáng Hương, Thư viện Quốc gia Pháp; ông Mai Anh Tuấn - Giảng viên Đại học Văn hóa Hà Nội; điều phối bởi GS Chu Hảo, nguyên Giám đốc NXB Tri thức.\n",
    "“Gần 20 năm qua, chúng tôi đã xuất bản gần 50 cuốn sách của các tác giả người Pháp. NXB Tri thức luôn dành tình cảm lớn trong việc thể hiện văn hóa và dấu ấn của văn hóa Pháp, và mong muốn được truyền tải đến Việt Nam trong thời gian qua và thời gian tới”, bà Phạm Thị Bích Hồng, Giám đốc NXB Tri thức cho  biết.\n",
    "Tại buổi tọa đàm, GS Chu Hảo nhận xét về sự thay đổi trong việc sử dụng ngoại ngữ hiện nay: “Sau một thời gian tiếng Anh hóa thì bây giờ các bạn trẻ quay lại với tiếng Pháp, Tây Ban Nha. Đó là một dấu hiệu tốt để đa dạng nền văn hóa. Tiếng Pháp được mệnh danh là một trong những ngôn ngữ lãng mạn nhất hành tinh, là thứ ngôn ngữ của tình yêu bởi sự tinh tế và thanh lịch\".\n",
    "TS. Dịch giả Nguyễn Giáng Hương nhận định rằng các tác giả người Pháp được NXB Tri Thức lựa chọn đều là những cá nhân đặc biệt. “Họ đại diện cho nền tư tưởng khoa học phương Tây. Tiêu biểu như Jean-Jacques Rousseau, một nhà triết học thuộc trường phái khai sáng, có ảnh hưởng lớn tới Cách mạng Pháp năm 1789. Ông cũng viết và đóng góp quan trọng cho trào lưu lãng mạn của văn học Pháp. Tác phẩm của Rousseau được đọc và nghiên cứu rộng rãi bởi chính cái nhìn sâu sắc về con người. Những lời bộc bạch đã mở đầu cho phong trào viết hồi ký hiện đại, tác động nhiều tới xu hướng này ở Việt Nam\".\n",
    "Với tư cách là một độc giả, ông Mai Anh Tuấn- Giảng viên Đại học Văn hóa Hà Nội háo hức khi đón nhận những cuốn sách dịch từ tiếng Pháp. Nhưng cũng có tâm lý e dè bởi đây là các tác phẩm không dễ đọc, đòi hỏi vượt qua bản thân để tiếp cận tri thức.\n",
    "Trước câu hỏi \"Phương pháp nào để giới trẻ tiếp cận những cuốn sách khó đọc trong Tủ sách Tinh hoa?\", diễn giả Mai Anh Tuấn nêu rõ 3 bước: lựa chọn sách gần với sự quan tâm và khả năng làm việc; đọc trực tiếp trên văn bản, khó thì dành nhiều công nghiên cứu kỹ hơn; bắt đầu vận dụng những cuốn sách vào công việc.\n",
    "TS. Dịch giả Nguyễn Giáng Hương bày tỏ mong muốn người đọc hãy chọn sách khéo léo: “Khi một NXB chọn cuốn nào, họ đều có lý do, vậy nên với tư cách là độc giả, chúng ta cũng phải có sở cứ của mình. Cần tìm hiểu tác giả là ai, dịch giả là ai, chọn tủ sách mình yêu thích phù hợp với sự tìm tòi của bản thân. Qua đó, hình thành thái độ đọc một cách chủ động, không mang tính dập khuôn, chịu sự áp đặt từ người khác”.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1 = \"\"\"我 们 一 起 去 动 物 园 吧\n",
    "小 明: 小 红 ，我 们 一 起 去 动 物 园 吧 ！\n",
    "\n",
    "小 红: 好 主 意！我 喜 欢 动 物 。什 么 时 候 去 ？\n",
    "\n",
    "小 明: 明 天 早 上 你 有 空 吗？\n",
    "\n",
    "小 红: 当 然 有 空 ！我 很 期 待 看 到 大 熊 猫。\n",
    "\n",
    "小 明: 我 也 想 看 大 熊 猫 ！我 们 明 天 早 上 九 点 见 面 ，好 吗？\n",
    "\n",
    "小 红: 好 的 ，九 点 在 动 物 园 门 口 见 面 。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [paragraph1]\n",
    "dictionary = create_dictionary(corpus)\n",
    "unknown_token_id = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [paragraph]\n",
    "dictionary = create_dictionary(corpus)\n",
    "unknown_token_id = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我',\n",
       " '们',\n",
       " '一',\n",
       " '起',\n",
       " '去',\n",
       " '动',\n",
       " '物',\n",
       " '园',\n",
       " '吧',\n",
       " '小',\n",
       " '明',\n",
       " '红',\n",
       " '，我',\n",
       " '！',\n",
       " '好',\n",
       " '主',\n",
       " '意！我',\n",
       " '喜',\n",
       " '欢',\n",
       " '。什',\n",
       " '么',\n",
       " '时',\n",
       " '候',\n",
       " '？',\n",
       " '天',\n",
       " '早',\n",
       " '上',\n",
       " '你',\n",
       " '有',\n",
       " '空',\n",
       " '吗？',\n",
       " '当',\n",
       " '然',\n",
       " '！我',\n",
       " '很',\n",
       " '期',\n",
       " '待',\n",
       " '看',\n",
       " '到',\n",
       " '大',\n",
       " '熊',\n",
       " '猫。',\n",
       " '也',\n",
       " '想',\n",
       " '猫',\n",
       " '九',\n",
       " '点',\n",
       " '见',\n",
       " '面',\n",
       " '，好',\n",
       " '的',\n",
       " '，九',\n",
       " '在',\n",
       " '门',\n",
       " '口',\n",
       " '。']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 56]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'thư viện'\n",
    "vectorize(text, dictionary, unknown_token_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "remove_characters = '\\t\"\"' + string.punctuation\n",
    "def text_normalize(text):\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = text.replace()\n",
    "    for char in remove_characters:\n",
    "        text = text.replace(char, '')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(corpus):\n",
    "    dictionary = []\n",
    "    for paragraph in corpus:\n",
    "        paragraph = text_normalize(paragraph)\n",
    "        tokens = paragraph.split()\n",
    "        for token in tokens:\n",
    "            if token not in dictionary:\n",
    "                dictionary.append(token)\n",
    "    \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(\n",
    "        text, \n",
    "        dictionary,\n",
    "        unknown_token_id\n",
    "):\n",
    "    text = text_normalize(text)\n",
    "    tokens = text.split()\n",
    "    vector = [\n",
    "        dictionary.index(token) \n",
    "        if token in dictionary else unknown_token_id \n",
    "            for token in tokens\n",
    "    ]\n",
    "\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
